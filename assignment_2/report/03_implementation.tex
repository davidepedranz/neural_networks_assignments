\section{Implementation}
\label{sec:implementation}

\subsection{Dataset Generation}
We use an artificially generated dataset with $P$ examples and $N$ features with normally distributed values.
The labels are not chosen randomly, but determined using a teacher weights vector $\bm{\mathsf{w}}^*$ as $S^\mu = sign(\mathsf{w}^{*} \cdotp \xi^\mu)$.
The obtained dataset is by construction linearly separable for $\bm{\mathsf{w}} = \bm{\mathsf{w}}^*$.

We chose $\bm{\mathsf{w}}^*$ such that its norm is constant, for example $||\bm{\mathsf{w}}^*||^2 = N$.
Since we initialize $\bm{\mathsf{w}} = \overrightarrow{0}$, we have that the distance between the student and the teacher perceptron is constant:
\begin{gather*}
    \bm{\mathsf{w}} = \overrightarrow{0} \in \mathbb{R}^N \\
    distance(\bm{\mathsf{w}}, \bm{\mathsf{w}}^*) = || \bm{\mathsf{w}} - \bm{\mathsf{w}}^* || = || \bm{\mathsf{w}}^*|| = \sqrt{N}
\end{gather*}
For simplicity, we chose $\bm{\mathsf{w}} = \overrightarrow{1} \in \mathbb{R}^N$.

\subsection{Perceptron Training}
To implement the Minover algorithm we started from the code written for the Rosenblatt perceptron in the last assignment.
As for the Rosenblatt perceptron, we initialize the weights vector of the student perceptron with zeros.
Then, we run the training procedure for number of epochs (where $epochs = n_{max} * P$).
At each epoch, we compute the stability of each example in the dataset (for performance reasons, we parallelize the computation as matrix operations instead of iterating over the elements in the dataset) and update the weights using the example with the minimum stability.
We terminate the training if the last update of the weights (normalized by the current norm) is smaller than a certain threshold (we chose $min_{update} = 0.001$), since the update is in practice never equal to zero for numerical problems.

The algorithm differs from the Rosenblatt's one since it performs an update at each step, whether the perceptron is already giving the correct classification or not (it could not have reached the optimum stability).

\subsection{Experiments}
For a fixed value of $P$ and $N$, $n_D$ independent datasets are generated. A new perceptron is trained on each dataset for at most $epochs = n_{max} * P$ epochs.
For each dataset, we compute the rate fraction $\in_g(t_{max})$ of generalization error. This error, calculated with the formula [\ref{eq:generalization_error}]
is a measure of how accurate the perceptron is in classifying previously unseen data, but in this case also means how distant it is from the teacher perceptron for those inputs.

Multiple experiments are run for different values of $P$ and $N$ in order to compute $in_g(t_{max})$ as a function of $\alpha = P / N$.
In other words, we studied the accuracy of the perceptron in classifying previously unseen inputs as a function of the rate between the number of examples and the dimension of the input.

\begin{equation} \label{eq:generalization_error}
    \in_g(t_{max}) = \frac{1}{\pi} \arccos \bigg(\frac{\bm{\mathsf{w}}(t_{max})\;\cdotp \bm{\mathsf{w}}^*}{\lvert \bm{\mathsf{w}}(t_{max}) \rvert \lvert \bm{\mathsf{w}}^* \rvert} \bigg)
\end{equation}

\subsection{Noisy dataset}
We decided to implement this bonus part because it's well known that in real classification problems the dataset provided to the perceptron is not perfect and can contain a certain
amount of noisy data. It's therefore of interest investing the performance of the two algorithms with that kind of data. The implementation consists in a small edit of the function
that generates the dataset. As it is possible to notice in the function below, we generated $P$ random values and then defined a vector called noise which contains
a label $-1$ if the probability (i.e. the randomly generated number) is smaller than $\lambda$ and $+1$ otherwise. A dot product is afterwards performed to introduce the noise in
the labels.