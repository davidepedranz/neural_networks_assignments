\lstset{language=Matlab,%
%basicstyle=\color{red},
breaklines=true,%
morekeywords={matlab2tikz},
keywordstyle=\color{blue},%
morekeywords=[2]{1}, keywordstyle=[2]{\color{black}},
identifierstyle=\color{black},%
stringstyle=\color{mylilas},
commentstyle=\color{mygreen},%
showstringspaces=false,%without this there will be a symbol in the places where there is a space
numbers=left,%
numberstyle={\tiny \color{black}},% size of the numbers
numbersep=9pt, % this defines how far the numbers are from the text
emph=[1]{for,end,break},emphstyle=[1]\color{blue}, %some words to emphasise
%emph=[2]{word1,word2}, emphstyle=[2]{style},    
}

\begin{appendices}
    \section{Matlab code}
        \subsection{MinOver algorithm}
        \begin{lstlisting}[language=Matlab]
            function [w, n_updates] = minover(X, y, n_max)
                % TRAIN_PERCEPTRON Train a perceptron on the dataset X, y for at most
                % (n_max * P) epochs using the MinOver algorithm.
            
                % stop the training unless at least one component of the weights
                % vector does not change significantly
                min_update = 0.001;
                
                % extract the number of examples P and number of dimensions (N)
                P = size(X, 1);
                N = size(X, 2);
                
                % initialize the weights to zero
                w = zeros(N, 1);
            
                % repeat training for any epochs
                epochs = n_max * P;
                for epoch = 1:epochs
                    
                    % compute stabilities k^{v(t)}
                    % NB: we do NOT divide by |w| since it is a constant for all
                    % examples and we only want to take the examples with the lowest
                    % stability
                    stabilities = (X * w) .* y;
                    
                    % keep track of the old weight we use this to stop the training
                    % if the weights do not change significantly for a training step
                    old_w = w;
                    
                    % extract the example with lowest stability
                    [~, index] = min(stabilities);
                    
                    % perform a Hebbian update step of the weights
                    example = X(index, :);
                    label = y(index);
                    w = old_w + (example' * label) / N;
                    
                    % stopping criteria: stop if there is no significant update
                    if all(norm(old_w - w) / norm(w) < min_update)
                        break
                    end
                end
                
                % we return the effective number of updates to complete the training
                n_updates = epoch;
            end
        \end{lstlisting}

        \newpage
        \subsection{Dataset generation basic implementation}
        \begin{lstlisting}[language=Matlab]
            function [X, y] = generate_dataset(P, N, w_star)
               X = randn(P, N);
               y = sign(X * w_star);
            end
        \end{lstlisting}

        \subsection{Dataset generation noisy data}
        \begin{lstlisting}[language=Matlab]
            function [X, y] = generate_dataset(P, N, w_star, lambda)
                prob = rand(P, 1);
                noise = iff(prob < lambda, -1, +1);
                X = randn(P, N);
                y = sign(X * w_star) .* noise;
            end
        \end{lstlisting}

\end{appendices}
